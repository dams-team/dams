{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c832df5",
   "metadata": {},
   "source": [
    "\n",
    "# Finetune SMAD Student (AST) End-to-End\n",
    "\n",
    "This notebook builds the fused pseudo-label manifest, validates it, trains the AST student, and evaluates on gold.\n",
    "\n",
    "**Assumptions**\n",
    "- Run from within the repo; audio segments live in `data/segments/`.\n",
    "- Dependencies installed: torch, torchaudio, transformers, pandas, datasets, scikit-learn.\n",
    "- Teachers HF datasets are under `data/metadata/blocs_smad_v2_*`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121b9ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project root: /Users/benji/Desktop/columbia/dams\n",
      "Working dir set to: /Users/benji/Desktop/columbia/dams\n"
     ]
    }
   ],
   "source": [
    "# Resolve project root and set paths\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / 'data').exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(f\"Using project root: {PROJECT_ROOT}\")\n",
    "import os\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f'Working dir set to: {Path.cwd()}')\n",
    "\n",
    "METADATA_DIR = PROJECT_ROOT / 'data/metadata'\n",
    "SEGMENTS_DIR = PROJECT_ROOT / 'data/segments'\n",
    "MANIFEST = METADATA_DIR / 'blocs_smad_v2_finetune.csv'\n",
    "GOLD = METADATA_DIR / 'blocs_smad_gold_annotations_v1.csv'\n",
    "CHECKPOINT = PROJECT_ROOT / 'checkpoints/student_ast.ipynb_run.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30a4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "AST_MODEL = 'MIT/ast-finetuned-audioset-10-10-0.4593'\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE_AST = 2\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "VAL_FRACTION = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22599db",
   "metadata": {},
   "source": [
    "\n",
    "## Build finetune manifest\n",
    "Uses `scripts/build_finetune_dataset.py`: per-class F1 winner on non-IRR gold; inner-join teachers; writes CSV/Parquet/HF dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec55130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using non-IRR calibration subset with 1569 rows\n",
      "Best speech teacher: m2d (F1 0.9592)\n",
      "Best music teacher: ast (F1 0.9768)\n",
      "Best noise teacher: clap (F1 0.0391)\n",
      "Teacher row counts: {'ast': 6196, 'clap': 6196, 'm2d': 6196, 'whisper': 6196}\n",
      "Segment intersection size across teachers: 6196\n",
      "Built merged dataset with 6196 rows and 34 columns\n",
      "Wrote Parquet to /Users/benji/Desktop/columbia/dams/data/metadata/blocs_smad_v2_finetune.parquet\n",
      "Wrote CSV to /Users/benji/Desktop/columbia/dams/data/metadata/blocs_smad_v2_finetune.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4a0688ca954f91853bcbe3b9293e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HF dataset to /Users/benji/Desktop/columbia/dams/data/metadata/blocs_smad_v2_finetune\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scripts.build_finetune_dataset import build_dataset\n",
    "\n",
    "out_disk = METADATA_DIR / 'blocs_smad_v2_finetune'\n",
    "out_parquet = METADATA_DIR / 'blocs_smad_v2_finetune.parquet'\n",
    "out_csv = MANIFEST\n",
    "\n",
    "build_dataset(METADATA_DIR, out_disk, out_parquet, out_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7013cf2",
   "metadata": {},
   "source": [
    "\n",
    "## Validate manifest\n",
    "Checks for dupes, required columns, chosen_* nulls, and optional gold sanity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9db4c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded manifest: data/metadata/blocs_smad_v2_finetune.csv rows=6196 columns=34\n",
      "No duplicate segment_path entries.\n",
      "All required teacher and chosen columns present.\n",
      "Chosen columns have no nulls.\n",
      "Value counts for chosen_speech_label: {1: 5698, 0: 498}\n",
      "Value counts for chosen_music_label: {0: 5488, 1: 708}\n",
      "Value counts for chosen_noise_label: {0: 6178, 1: 18}\n",
      "Merged IRR gold rows: 174\n",
      "\n",
      "IRR gold sanity for speech:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8718    1.0000    0.9315        34\n",
      "           1     1.0000    0.9643    0.9818       140\n",
      "\n",
      "    accuracy                         0.9713       174\n",
      "   macro avg     0.9359    0.9821    0.9567       174\n",
      "weighted avg     0.9749    0.9713    0.9720       174\n",
      "\n",
      "\n",
      "IRR gold sanity for music:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9746    1.0000    0.9871       115\n",
      "           1     1.0000    0.9492    0.9739        59\n",
      "\n",
      "    accuracy                         0.9828       174\n",
      "   macro avg     0.9873    0.9746    0.9805       174\n",
      "weighted avg     0.9832    0.9828    0.9826       174\n",
      "\n",
      "\n",
      "IRR gold sanity for noise:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8728    0.9934    0.9292       152\n",
      "           1     0.0000    0.0000    0.0000        22\n",
      "\n",
      "    accuracy                         0.8678       174\n",
      "   macro avg     0.4364    0.4967    0.4646       174\n",
      "weighted avg     0.7625    0.8678    0.8117       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scripts.validate_finetune_manifest import main as validate_main\n",
    "validate_main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab18d75",
   "metadata": {},
   "source": [
    "\n",
    "## Train AST student\n",
    "Fine-tune AST with BCEWithLogits, class pos_weight, train/val split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bc4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/torchaudio/functional/functional.py:582: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n",
      "Some weights of ASTForAudioClassification were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
      "- classifier.dense.bias: found shape torch.Size([527]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.dense.weight: found shape torch.Size([527, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/benji/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434d0fb79cbf4c36af0fcf5b6f3098a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/10:   0%|          | 0/2789 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x107057a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benji/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 255, in __iter__\n",
      "    self.disp(bar_style='danger')\n",
      "  File \"/Users/benji/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 139, in display\n",
      "    def display(self, msg=None, pos=None,\n",
      "  File \"/Users/benji/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 8466) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain_student\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m      4\u001b[39m train_args = argparse.Namespace(\n\u001b[32m      5\u001b[39m     manifest=MANIFEST,\n\u001b[32m      6\u001b[39m     segments_dir=SEGMENTS_DIR,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     ast_model=AST_MODEL,\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/columbia/dams/scripts/train_student.py:96\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     94\u001b[39m loss = criterion(logits, labels)\n\u001b[32m     95\u001b[39m optim.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m optim.step()\n\u001b[32m     98\u001b[39m running_loss += loss.item() * input_values.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/columbia/dams/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "from scripts.train_student import train\n",
    "\n",
    "train_args = argparse.Namespace(\n",
    "    manifest=MANIFEST,\n",
    "    segments_dir=SEGMENTS_DIR,\n",
    "    sample_rate=16000,\n",
    "    n_mels=128,\n",
    "    hop_length=160,\n",
    "    win_length=400,\n",
    "    batch_size_ast=BATCH_SIZE_AST,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    val_fraction=VAL_FRACTION,\n",
    "    output=CHECKPOINT,\n",
    "    ast_model=AST_MODEL,\n",
    ")\n",
    "train(train_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29438458",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate on gold\n",
    "Default filter is IRR; adjust `gold_filter` or `threshold` as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "from scripts.evaluate_student import evaluate\n",
    "\n",
    "eval_args = argparse.Namespace(\n",
    "    checkpoint=CHECKPOINT,\n",
    "    manifest=MANIFEST,\n",
    "    segments_dir=SEGMENTS_DIR,\n",
    "    gold=GOLD,\n",
    "    gold_filter='irr',  # options: 'irr', 'non-irr', 'all'\n",
    "    batch_size=2,\n",
    "    threshold=0.5,\n",
    "    sample_rate=16000,\n",
    "    ast_model=AST_MODEL,\n",
    ")\n",
    "evaluate(eval_args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
