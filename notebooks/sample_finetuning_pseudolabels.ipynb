{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ce204d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7c885",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import (\n",
    "    AutoFeatureExtractor,\n",
    "    AutoModelForAudioClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.config_utils import load_env, add_project_root_to_path\n",
    "load_env()\n",
    "\n",
    "from config import get_settings, AST_MODEL_NAME, SAMPLE_RATE\n",
    "from utils.dams_types import (\n",
    "    SPEECH,\n",
    "    MUSIC,\n",
    "    NOISE,\n",
    "    SPEECH_SCORE,\n",
    "    MUSIC_SCORE,\n",
    "    NOISE_SCORE,\n",
    "    SEGMENT_PATH,\n",
    "    BLOCS_SMAD_V2_M2D,\n",
    "    BLOCS_SMAD_V2_AST,\n",
    "    BLOCS_SMAD_V2_CLAP,\n",
    "    BLOCS_SMAD_V2_WHISPER,\n",
    ")\n",
    "from utils.audio_io import load_mono_resampled\n",
    "\n",
    "# Ensure project root is in path\n",
    "add_project_root_to_path()\n",
    "\n",
    "settings = get_settings()\n",
    "metadata_dir = Path(settings.metadata_path)\n",
    "segments_dir = Path(settings.segments_path)\n",
    "\n",
    "print(f\"Metadata directory: {metadata_dir}\")\n",
    "print(f\"Segments directory: {segments_dir}\")\n",
    "\n",
    "# Device setup\n",
    "def get_device() -> torch.device:\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aea5a4",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Change the CSV file here to switch data sources.** The CSV file should be in `data/metadata/` directory.\n",
    "\n",
    "The notebook supports two formats:\n",
    "1. **New format** (recommended): `blocs_smad_v2_finetune.csv` with `chosen_speech_label`, `chosen_music_label`, `chosen_noise_label` columns\n",
    "2. **Old format**: Files like `blocs_smad_v2_m2d.csv`, `blocs_smad_v2_ast.csv`, etc. with `speech_label`, `music_label`, `noise_label` columns\n",
    "\n",
    "The notebook will automatically detect which format you're using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION: Change this to switch CSV files\n",
    "# ============================================\n",
    "CSV_FILE = \"blocs_smad_v2_finetune.csv\"  # Change this to your desired CSV file\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 10\n",
    "WEIGHT_DECAY = 0.01\n",
    "TRAIN_SPLIT = 0.8  # 80% train, 20% validation\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Model configuration\n",
    "NUM_CLASSES = 3  # [speech, music, noise]\n",
    "FREEZE_ENCODER = False  # Set to True to freeze AST encoder and only train head\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = metadata_dir / CSV_FILE\n",
    "print(f\"Loading data from: {csv_path}\")\n",
    "\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a18c3",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Create a PyTorch Dataset class that loads audio segments and their labels from the CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f160613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudolabelDataset(Dataset):\n",
    "    \"\"\"Dataset for loading audio segments and multilabel targets from CSV.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        segments_dir: Path,\n",
    "        feature_extractor: AutoFeatureExtractor,\n",
    "        use_scores: bool = False,\n",
    "        use_chosen_labels: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame with columns: segment_path, chosen_speech_label, chosen_music_label, chosen_noise_label\n",
    "                (or speech_label, music_label, noise_label for old format)\n",
    "            segments_dir: Directory containing audio segment files\n",
    "            feature_extractor: AST feature extractor for preprocessing\n",
    "            use_scores: If True, use continuous scores instead of binary labels\n",
    "            use_chosen_labels: If True, use chosen_* columns (new format), else use old format columns\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.segments_dir = segments_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.use_scores = use_scores\n",
    "        self.use_chosen_labels = use_chosen_labels\n",
    "        \n",
    "        # Determine column names based on format\n",
    "        if use_chosen_labels:\n",
    "            self.speech_col = 'chosen_speech_label'\n",
    "            self.music_col = 'chosen_music_label'\n",
    "            self.noise_col = 'chosen_noise_label'\n",
    "            self.speech_score_col = 'chosen_speech_score'\n",
    "            self.music_score_col = 'chosen_music_score'\n",
    "            self.noise_score_col = 'chosen_noise_score'\n",
    "        else:\n",
    "            # Fallback to old format\n",
    "            self.speech_col = SPEECH\n",
    "            self.music_col = MUSIC\n",
    "            self.noise_col = NOISE\n",
    "            self.speech_score_col = SPEECH_SCORE\n",
    "            self.music_score_col = MUSIC_SCORE\n",
    "            self.noise_score_col = NOISE_SCORE\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_cols = [SEGMENT_PATH, self.speech_col, self.music_col, self.noise_col]\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        segment_path = self.segments_dir / row[SEGMENT_PATH]\n",
    "        \n",
    "        # Load audio\n",
    "        waveform = load_mono_resampled(segment_path, target_sr=SAMPLE_RATE)\n",
    "        \n",
    "        # Preprocess with feature extractor\n",
    "        inputs = self.feature_extractor(\n",
    "            waveform.numpy(),\n",
    "            sampling_rate=SAMPLE_RATE,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "        )\n",
    "        \n",
    "        # Extract labels\n",
    "        if self.use_scores and all(col in row for col in [self.speech_score_col, self.music_score_col, self.noise_score_col]):\n",
    "            labels = torch.tensor([\n",
    "                row[self.speech_score_col],\n",
    "                row[self.music_score_col],\n",
    "                row[self.noise_score_col]\n",
    "            ], dtype=torch.float32)\n",
    "        else:\n",
    "            labels = torch.tensor([\n",
    "                int(row[self.speech_col]),\n",
    "                int(row[self.music_col]),\n",
    "                int(row[self.noise_col])\n",
    "            ], dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            'input_values': inputs['input_values'].squeeze(0),\n",
    "            'labels': labels,\n",
    "            'segment_path': row[SEGMENT_PATH]\n",
    "        }\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(AST_MODEL_NAME)\n",
    "print(\"Feature extractor initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7734635",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Create an AST-based encoder with a custom classification head for 3-class multilabel classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e67a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTStudentClassifier(nn.Module):\n",
    "    \"\"\"AST encoder with custom classification head for multilabel classification.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = AST_MODEL_NAME,\n",
    "        num_classes: int = 3,\n",
    "        freeze_encoder: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained AST model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        self.encoder = AutoModelForAudioClassification.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "        )\n",
    "        \n",
    "        # Get the hidden size from the encoder\n",
    "        # AST models typically have a classifier head, we'll replace it\n",
    "        hidden_size = config.hidden_size\n",
    "        \n",
    "        # Remove the original classification head (if it exists)\n",
    "        if hasattr(self.encoder, 'classifier'):\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif hasattr(self.encoder, 'projector'):\n",
    "            self.encoder.projector = nn.Identity()\n",
    "        \n",
    "        # Create new classification head for 3-class multilabel\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Freeze encoder if requested\n",
    "        if freeze_encoder:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"Encoder frozen, only training classification head\")\n",
    "        else:\n",
    "            print(\"Training full model (encoder + head)\")\n",
    "    \n",
    "    def forward(self, input_values):\n",
    "        # Get encoder outputs with output_hidden_states to access features\n",
    "        outputs = self.encoder(\n",
    "            input_values,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        \n",
    "        # Extract pooled features from the last hidden state\n",
    "        # AST models have hidden_states in the outputs when output_hidden_states=True\n",
    "        if hasattr(outputs, 'hidden_states') and outputs.hidden_states is not None:\n",
    "            # Use last hidden state (from the transformer encoder)\n",
    "            last_hidden_state = outputs.hidden_states[-1]  # [batch, seq_len, hidden_size]\n",
    "            # Average pooling over sequence dimension\n",
    "            pooled = last_hidden_state.mean(dim=1)  # [batch, hidden_size]\n",
    "        else:\n",
    "            # Fallback: access the base transformer model directly\n",
    "            # AST models have audio_spectrogram_transformer attribute\n",
    "            if hasattr(self.encoder, 'audio_spectrogram_transformer'):\n",
    "                transformer = self.encoder.audio_spectrogram_transformer\n",
    "                # Get embeddings\n",
    "                embeddings = transformer.embeddings(input_values)\n",
    "                # Pass through encoder\n",
    "                encoder_outputs = transformer.encoder(embeddings, output_hidden_states=True)\n",
    "                # Get last hidden state and pool\n",
    "                last_hidden_state = encoder_outputs.last_hidden_state\n",
    "                pooled = last_hidden_state.mean(dim=1)\n",
    "            else:\n",
    "                # Last resort: try to get features from model outputs\n",
    "                # Some AST models might have different structure\n",
    "                raise NotImplementedError(\n",
    "                    f\"Could not extract features from AST model. \"\n",
    "                    f\"Model structure: {type(self.encoder)}. \"\n",
    "                    f\"Available attributes: {dir(self.encoder)}\"\n",
    "                )\n",
    "        \n",
    "        # Apply classification head\n",
    "        logits = self.classifier(pooled)\n",
    "        return logits\n",
    "\n",
    "# Initialize model\n",
    "model = ASTStudentClassifier(\n",
    "    model_name=AST_MODEL_NAME,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    freeze_encoder=FREEZE_ENCODER,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model initialized on {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44710fa",
   "metadata": {},
   "source": [
    "## Prepare Data Splits\n",
    "\n",
    "Split the data into train and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with missing data\n",
    "# Check which format we're using (new format with chosen_* or old format)\n",
    "if 'chosen_speech_label' in df.columns:\n",
    "    label_cols = ['chosen_speech_label', 'chosen_music_label', 'chosen_noise_label']\n",
    "    use_chosen = True\n",
    "    print(\"Using new format: chosen_* columns\")\n",
    "else:\n",
    "    label_cols = [SPEECH, MUSIC, NOISE]\n",
    "    use_chosen = False\n",
    "    print(\"Using old format: speech_label, music_label, noise_label\")\n",
    "\n",
    "df_clean = df.dropna(subset=[SEGMENT_PATH] + label_cols)\n",
    "print(f\"After filtering: {len(df_clean)} samples\")\n",
    "\n",
    "# Split into train and validation\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "indices = np.random.permutation(len(df_clean))\n",
    "split_idx = int(len(df_clean) * TRAIN_SPLIT)\n",
    "train_indices = indices[:split_idx]\n",
    "val_indices = indices[split_idx:]\n",
    "\n",
    "df_train = df_clean.iloc[train_indices].reset_index(drop=True)\n",
    "df_val = df_clean.iloc[val_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train samples: {len(df_train)}\")\n",
    "print(f\"Validation samples: {len(df_val)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PseudolabelDataset(\n",
    "    df_train,\n",
    "    segments_dir,\n",
    "    feature_extractor,\n",
    "    use_scores=False,  # Use binary labels\n",
    "    use_chosen_labels=use_chosen,  # Use chosen_* format if available\n",
    ")\n",
    "\n",
    "val_dataset = PseudolabelDataset(\n",
    "    df_val,\n",
    "    segments_dir,\n",
    "    feature_extractor,\n",
    "    use_scores=False,\n",
    "    use_chosen_labels=use_chosen,  # Use chosen_* format if available\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for compatibility, increase if needed\n",
    "    pin_memory=True if device.type == 'cuda' else False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if device.type == 'cuda' else False,\n",
    ")\n",
    "\n",
    "print(\"Data loaders created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890d6d6",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "Initialize loss function, optimizer, and scheduler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404489b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: BCEWithLogitsLoss for multilabel classification\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCHS,\n",
    "    eta_min=LEARNING_RATE * 0.01,\n",
    ")\n",
    "\n",
    "print(\"Training setup complete\")\n",
    "print(f\"Loss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer}\")\n",
    "print(f\"Scheduler: {scheduler}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa4b14",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the model with validation monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "}\n",
    "\n",
    "def compute_accuracy(logits, labels, threshold=0.5):\n",
    "    \"\"\"Compute multilabel accuracy with threshold.\"\"\"\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs >= threshold).float()\n",
    "    # Exact match accuracy (all labels must match)\n",
    "    correct = (preds == labels).all(dim=1).float()\n",
    "    return correct.mean().item()\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Run validation.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "            input_values = batch['input_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits = model(input_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += compute_accuracy(logits, labels)\n",
    "            num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches, total_acc / num_batches\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
    "    for batch in progress_bar:\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_values)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        train_loss += loss.item()\n",
    "        train_acc += compute_accuracy(logits, labels)\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{compute_accuracy(logits, labels):.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_train_loss = train_loss / num_batches\n",
    "    avg_train_acc = train_acc / num_batches\n",
    "    \n",
    "    # Validation phase\n",
    "    avg_val_loss, avg_val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['train_acc'].append(avg_train_acc)\n",
    "    history['val_acc'].append(avg_val_acc)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {avg_val_acc:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model (you can add model saving here)\n",
    "        print(\"âœ“ New best validation loss!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Training complete!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec66755",
   "metadata": {},
   "source": [
    "## Training Curves\n",
    "\n",
    "Visualize training and validation loss/accuracy over epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best validation loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"Best validation accuracy: {max(history['val_acc']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8fe07",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the model on the validation set with detailed metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    multilabel_confusion_matrix,\n",
    "    hamming_loss,\n",
    "    jaccard_score,\n",
    ")\n",
    "\n",
    "def evaluate_model(model, val_loader, device, threshold=0.5):\n",
    "    \"\"\"Comprehensive model evaluation.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            input_values = batch['input_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits = model(input_values)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= threshold).float()\n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "    \n",
    "    # Classification report\n",
    "    class_names = ['speech', 'music', 'noise']\n",
    "    print(\"Classification Report (per class):\")\n",
    "    print(classification_report(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        target_names=class_names,\n",
    "        zero_division=0\n",
    "    ))\n",
    "    \n",
    "    # Multilabel metrics\n",
    "    print(f\"\\nHamming Loss: {hamming_loss(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Jaccard Score (micro): {jaccard_score(all_labels, all_preds, average='micro'):.4f}\")\n",
    "    print(f\"Jaccard Score (macro): {jaccard_score(all_labels, all_preds, average='macro'):.4f}\")\n",
    "    print(f\"Jaccard Score (per class): {jaccard_score(all_labels, all_preds, average=None)}\")\n",
    "    \n",
    "    # Exact match accuracy\n",
    "    exact_match = (all_preds == all_labels).all(axis=1).mean()\n",
    "    print(f\"\\nExact Match Accuracy: {exact_match:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs,\n",
    "    }\n",
    "\n",
    "# Run evaluation\n",
    "eval_results = evaluate_model(model, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4a766",
   "metadata": {},
   "source": [
    "## Save Model (Optional)\n",
    "\n",
    "Save the trained model for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b15dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save the model\n",
    "# model_save_path = settings.models_path / f\"ast_student_{CSV_FILE.replace('.csv', '')}.pt\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'history': history,\n",
    "#     'config': {\n",
    "#         'num_classes': NUM_CLASSES,\n",
    "#         'freeze_encoder': FREEZE_ENCODER,\n",
    "#         'csv_file': CSV_FILE,\n",
    "#     }\n",
    "# }, model_save_path)\n",
    "# print(f\"Model saved to: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f54df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
